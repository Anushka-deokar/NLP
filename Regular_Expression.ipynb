{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "467b4d4a-687e-4098-96b5-ab6ea56598c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"The agent's phone number is 408-555-1234. Call soon!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867685b-f38e-4e41-bd46-b907011e754c",
   "metadata": {},
   "source": [
    "Will start of by trying to find out if the string \"phone\" is inside the text string.now we could do this quicl;y with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a79ceb-5b9c-45c1-8b2b-276c7333beea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'phone' in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb29706b-9f01-4d71-82fa-8f5ab2adee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33122d9b-e992-4193-9df1-6d8536eeced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'phone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7778525-fc38-420a-a122-aab33a80b1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c469ae5e-bbc6-47bc-a046-ea1a1e94098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"NOT IN TEXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87407d25-8e07-4968-99fd-07a6db147f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d5435-62f4-45f3-87df-124499d108cc",
   "metadata": {},
   "source": [
    "Now we have seen the that re.search() will take the pattern,scan the text,and then returns a match object.If no pattern is found,a none is returnd(in jupyter notebook this is just means that noting is output bellow the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4e5f562-6004-4ce9-8371-668d783c5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern ='phone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afb02153-be44-4275-b444-ffe30490e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "954a53f9-acea-4f78-acff-2a33cc7ca882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeef8b7c-ecb1-4704-96a8-acebd08cda16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbdd20df-41f7-4929-a7f5-0e03e652f538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bb4752-8958-474b-a809-de4a00290c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28493d-45b8-4026-826b-f49269b30331",
   "metadata": {},
   "source": [
    "But what if the pattern occurs more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d269178-2ccf-43c2-8453-e518126930b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my phone is a new phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "872ab10b-75c8-4f63-944b-868139c14f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(\"phone\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7166e769-ae69-4d3a-b068-24f3c58d8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bb0a6-f517-41ef-a41e-aa9b98637dd9",
   "metadata": {},
   "source": [
    "Notice it once matchs the first instance.If we wanted a list of all matches ,we can use .findall() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "471913b0-8176-47af-b959-d648d65336a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(\"phone\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d21d2b0c-4e8c-4977-9089-57ef7668834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'phone']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9d1f775-5ed8-4074-bb69-b7677f1be2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a35c9-4ae6-43f1-b667-a1ecad09fef5",
   "metadata": {},
   "source": [
    "to get actual objects use the iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc95866d-c22c-4ced-a8c3-65844cd6a1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(18, 23)\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(\"phone\",text):\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234a50d-15e7-430a-8dab-c02a20625477",
   "metadata": {},
   "source": [
    "If we wanted the actual text that matches you can use the .group() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ebe21f2-4d80-437c-a826-c709935c1f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phone'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f0f84-4583-4497-b184-0f7383ba9850",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74803344-8392-4f26-a279-078782483b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My telephone number is 408-555-1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cfbf370-b79b-4906-b1e1-1d718a3c73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = re.search(r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e0e80ea-e8d0-431f-b535-0860517ad1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "623facb0-9e43-48b3-a5f2-b43a56d527bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d{3}-\\d{3}-\\d{4}',text) #it is used for regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b1f51-c862-4ed2-989f-f976a220c96b",
   "metadata": {},
   "source": [
    "Groups what if we we wanted to do 2 tasks, find phone numbers but also  be able to quickly extract their area code(first 3 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c240442-10ad-4197-84af-8ae75706082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_pattern = re.compile(r'(\\d{3})-(\\d{3})-(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ed95e6b-2008-4d9d-ab14-797a16ef0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.search(phone_pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00ae9916-da61-498f-9c26-54276c204d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a9d48ec-52e4-42df-a74d-0d581cf8323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1750e406-cb4a-4dc2-96c7-93773e403dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'555'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "636dd9e3-4b08-4094-8f25-a99a161d1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b076eff-9fd0-4964-aaa1-40e6a054c733",
   "metadata": {},
   "source": [
    "Or operator | Use the pipe operator to have an a statment.For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54147b56-47f5-4b98-b0c1-ad93c4239809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(8, 11), match='man'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|women\",\"This is man  here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "187ff227-fea1-4220-9f7c-5b549beb769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(10, 15), match='women'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|women\",\"This is a women here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68602e-0d27-453a-866a-d9f7b7fda8b8",
   "metadata": {},
   "source": [
    "The Wildcard Character Use a \"Wildcard\" as a placement that will match any character placed there.U can use a simple period. for this .For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a7eb66-6074-495f-ac0f-aec1276e8719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'hat', 'sat']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The cat in the hat sat here.\") #one letter before at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d4cbb93-1ec6-43a2-adf3-74a155e809eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'lat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The bat went splat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e42b7dc-4599-4ab3-a34e-e36c5481fc99",
   "metadata": {},
   "source": [
    "Notice we only matched the first 3 letters,that is beacause we need a . for each wildcard letter. Or use the quantifiers described above to set its own rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b967470-7cfe-4c13-9248-09231d29addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e bat', 'splat']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"...at\",\"The bat went splat\")  #three leter before at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8602ed48-7e4a-44cb-b460-46fe47f8e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'splat']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one or more non whitespace that ends with 'at'\n",
    "re.findall(r'\\S+at',\"This  bat went splat\") #we have removed \"e bat\" e is removed as its useless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6324d-b9b7-486d-851e-ae06aee29f2e",
   "metadata": {},
   "source": [
    "Starts with and Ends with We can use the ^ to sinal starts with,and the $ to signal ends with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58905013-7a86-4afb-8312-097d9a882b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ends with a number\n",
    "re.findall(r'\\d$','THis ends with a number 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8046897-aa99-4302-adf0-c876244adf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starts with a number\n",
    "re.findall(r'^\\d','1 is the loneliest number.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2711995-34bd-434e-ae0b-e6f18d00884b",
   "metadata": {},
   "source": [
    "Exclusion to exclude characters, we can use the ^ symbols in conjuctions with a set of brackets[].\n",
    "Anything inside the bracket is executed.For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7dd9fd3-2638-424c-af27-7bf87dfd3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"There are 3 numbers 34 inside 5 this sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d488bc8b-b823-4846-822f-dba4b9ec7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.findall(r'[^\\d]+',phrase) #if we dont include +sing all the text will be printed word by word in horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1221979-cd77-4c01-9f16-b9661a150c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are ', ' numbers ', ' inside ', ' this sentence.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410eafa-24e6-4bfb-9294-27249128b503",
   "metadata": {},
   "source": [
    "To get the words back together use + sign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fa56fa0-1aed-4798-8162-a01bf1724a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function re.findall(pattern, string, flags=0)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db0c633f-803a-4a4b-bd70-36d03630ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_phrase = \"This is a string ! But it has puctuation. How can we remove it ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51ea8f80-08f0-4872-bdc2-fe47402d989f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a string ', ' But it has puctuation', ' How can we remove it ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[^!.?]+',t_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596f612-bd8b-4492-abb5-ab5df46c58f0",
   "metadata": {},
   "source": [
    "### Join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ef91796-f4d2-4cfa-98f6-b5fd70644996",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = ' '.join(re.findall('[^!.?]+',t_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62ce08e4-6b2e-4ed4-b03d-136fffc0625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string   But it has puctuation  How can we remove it '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22a0e0b9-6b80-4869-ba7d-29b3b4cbbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the words that start with cat and end with one of these options: 'fish', '\n",
    "text = \"Hello, would you like some catfish?\"\n",
    "texttwo = \"Hello, would you like to take a catnap?\"\n",
    "textthree = \"Hello, have you seen this caterpiller?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a68b9730-a3e8-45db-8a3c-0ee0fd792b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(27, 34), match='catfish'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'cat(fish|nap|claw)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98899a53-c6e1-485d-aaac-31ce5e7b175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(32, 38), match='catnap'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'cat(fish|nap|claw)',texttwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4fb5f0e-dd39-41f9-ba94-ed0db0681502",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'cat(fish|nap|claw)',textthree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f029ce-256e-4cdc-9b74-d763d38f6924",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcb66685-eacc-4b20-ab20-60772e3fd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U spacy\n",
    "#conda install -c conda-forge spacy\n",
    "#python -m spacy downlaod en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee7b18-3198-498e-ad7f-b0e5f49c5943",
   "metadata": {},
   "source": [
    "### Token Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a55417a8-1f61-4d0d-943c-dd34e60ca8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sai\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import spaCy and load the language library\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Create a Doc object \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\compat.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\config.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mregistry\u001b[39;00m(confection\u001b[38;5;241m.\u001b[39mregistry):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     optimizers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\types.py:25\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     Any,\n\u001b[0;32m      6\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     overload,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy, has_cupy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_cupy:\n\u001b[0;32m     28\u001b[0m     get_array_module \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39mget_array_module\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\compat.py:35\u001b[0m\n\u001b[0;32m     31\u001b[0m     has_cupy_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdlpack\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     has_torch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sai\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "#Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Create a Doc object \n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup to $6 million')\n",
    "\n",
    "#Print each token seperately\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f55238-989a-4215-935c-87e4ee7d43c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7028e7db-8701-47a5-b455-41cdf34ed534",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sai\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Import spaCy and load the language library\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Create a Doc object \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\compat.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\config.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mregistry\u001b[39;00m(confection\u001b[38;5;241m.\u001b[39mregistry):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     optimizers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\types.py:25\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     Any,\n\u001b[0;32m      6\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     overload,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy, has_cupy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_cupy:\n\u001b[0;32m     28\u001b[0m     get_array_module \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39mget_array_module\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\compat.py:35\u001b[0m\n\u001b[0;32m     31\u001b[0m     has_cupy_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdlpack\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     has_torch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sai\\anaconda3\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "#Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Create a Doc object \n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup to $6 million')\n",
    "\n",
    "#Print each token sperately\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bc105-3358-4067-8fce-5403061ec17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Create a Doc object \n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup to $6 million')\n",
    "\n",
    "#Print each token speratly\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_, token.dep_)\n",
    "    #predict syntactic dependencies\n",
    "    #predictating syntactic dependencies involves\n",
    "    #identifing the grammetical structure of a \n",
    "    #sentence by determining how different words relate to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14064d-357a-4de8-b150-23fdc646942e",
   "metadata": {},
   "source": [
    "### NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f56519-fd40-4973-ad89-124af2c28a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp\u001b[38;5;241m.\u001b[39mpipeline\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1488d4-abe1-4f17-b64b-8156480374a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp\u001b[38;5;241m.\u001b[39mpipe_names\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49927aeb-f130-4584-835d-a1060d2df636",
   "metadata": {},
   "source": [
    "Tokenization - The first step in processing text is to split up all the component parts( words & punctuation) into \"tokens\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05da576d-9a62-41cc-90e4-1a44d9968f2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc2 \u001b[38;5;241m=\u001b[39mnlp(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesla isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt     looking into startups anymore.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc2:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token\u001b[38;5;241m.\u001b[39mtext, token\u001b[38;5;241m.\u001b[39mpos_, token\u001b[38;5;241m.\u001b[39mdep_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "doc2 =nlp(u\"Tesla isn't     looking into startups anymore.\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9440246-a717-4a02-a435-ae7828233071",
   "metadata": {},
   "source": [
    "Notice how isn't has been spit into two tokens, spacy recognizes both the root verb is and the negation attached to it. Notice also that both the extended whitespace and the period at the end of the sentence are assigned therir own tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09f5eb3-4c8b-4842-bbd1-343b0b92c659",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc2' is not defined"
     ]
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc0cb569-e008-4067-b047-a0733d3a4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93a41e25-46b1-4574-8e0f-0d4374099b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e7cf134-7390-437e-8942-bfc1379e25f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf5da176-e874-480e-a967-2b3828e66074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1674f6b7-9545-4167-bcc0-f28b4d24aa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973804e5-2ae7-41ff-a565-55fb4613f290",
   "metadata": {},
   "source": [
    "### Part-of-Speech(POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc6012-6d5e-4b7d-b90a-4c31e0548bed",
   "metadata": {},
   "source": [
    "Part-of-Speech Tagging (POS) The next step har spillting the text up in ons is to assign parts of speech in the above example, Tenis was recognized to be a proper noun. Here some statical modeling is reqared. For example, words that follow \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1926371-3999-47d6-97ca-0b40d46ede00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spacy.io/usage/linguistic-features#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d497276f-6432-41c9-8d44-b63120dbcc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "#Lemmas(the base form of the word\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1136f-cb4a-45c3-8879-c176ab4ed490",
   "metadata": {},
   "source": [
    "Spans\n",
    "Large Doc objects can be hard to work with at times .A span is a slice of Doc object in the form Doc[start:stop]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bbbaafd7-9911-4cf3-8430-32ba4a86b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \" 2 the phrase \"Life is what happens to us while we are making other plans\" was 3 cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8a16283e-2045-474f-92e9-9ab9bc20c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what happens to us while we are making other plans\" was 3 cartoonist\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "13a3b0b9-2654-40d3-8b36-5fc970ad88fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5eff4d3a-cabc-4766-b6b7-87261d153539",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is the another sentence.This is the last sentencs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "279998b6-574b-4045-89fe-9baa7d9905a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the anoyher sentence.\n",
      "This is the last sentencs\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bd72c-274d-4fcc-a481-d0ef06dad177",
   "metadata": {},
   "source": [
    "Tokenization :- This is the first step in creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cadcc418-481b-4d0f-b3e8-dcccad4bc23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We 're moving to L.A!\"\n"
     ]
    }
   ],
   "source": [
    "#Create a string that includes opening and closing quotation marks\n",
    "mystring='\"We \\'re moving to L.A!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3d5ca76-15da-43d6-ae31-dd9a6e4283d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A | ! | \" | "
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for token in doc:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f39dd7ab-651e-484e-b67a-55b7d3ffd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we | 're | here | to | help | ! | Send | snail | - | mail | , | email | support@oursite.com | or | visit | us | at | http://www.oursite.com | ! | "
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"we're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "for token in doc2:\n",
    "    print(token.text, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c059cc47-7110-4893-b44b-435b452ca42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5Km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'A 5Km NYC cab ride costs $10.30')\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fde1bfb-ab68-442a-8b41-a0c79c976ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66aefe3-01a3-4e3f-8f55-8ef0163bfc6d",
   "metadata": {},
   "source": [
    "Here the distance until and dollar sign are assigned their own tokens,yet the doller amount is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579d20e-989a-4921-a719-e403afdbe8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
